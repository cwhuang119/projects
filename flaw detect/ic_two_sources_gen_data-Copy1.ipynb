{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shuoh\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, Conv2D, Dropout, MaxPooling2D, Flatten\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 將訓練資料匯入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image in ng2: (228, 112, 160, 3)\n",
      "image in ng1: (926, 112, 160, 3)\n",
      "image in ok2: (252, 112, 160, 3)\n",
      "image in ok1: (1001, 112, 160, 3)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "ng2 = os.listdir(\"IC2/ng2\")\n",
    "ok2 = os.listdir(\"IC2/ok2\")\n",
    "ng1 = os.listdir(\"IC1/ng\")\n",
    "ok1 = os.listdir(\"IC1/ok\")\n",
    "ok2_gen = os.listdir(\"IC2/ok2_gen\")\n",
    "ng2_gen = os.listdir(\"IC2/ng2_gen\")\n",
    "\n",
    "img_ng2=[]\n",
    "img_ng1=[]\n",
    "img_ok2=[]\n",
    "img_ok1=[]\n",
    "\n",
    "for img in ng2:\n",
    "    ng = cv2.imread(\"IC2/ng2/\"+img)\n",
    "    ng = cv2.resize(ng, (160,112), interpolation=cv2.INTER_AREA)\n",
    "#     ng = ng.resize()\n",
    "#     print(ng)\n",
    "    img_ng2.append(ng)\n",
    "for img in ng2_gen:\n",
    "    ng = cv2.imread(\"IC2/ng2_gen/\"+img)\n",
    "    ng = cv2.resize(ng, (160,112), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "#     ng = ng.resize()\n",
    "#     print(ng)\n",
    "    img_ng2.append(ng)\n",
    "img_ng2 = np.array(img_ng2)\n",
    "print('image in ng2:',img_ng2.shape)\n",
    "\n",
    "for img in ng1:\n",
    "    ng = cv2.imread(\"IC1/ng/\"+img)\n",
    "    ng = cv2.resize(ng, (160,112), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "#     print(ng)\n",
    "    img_ng1.append(ng)\n",
    "img_ng1 = np.array(img_ng1)\n",
    "print('image in ng1:',img_ng1.shape)\n",
    "\n",
    "\n",
    "for img in ok2:\n",
    "    ng = cv2.imread(\"IC2/ok2/\"+img)\n",
    "    ng = cv2.resize(ng, (160,112), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "#     print(ng)\n",
    "    img_ok2.append(ng)\n",
    "for img in ok2_gen:\n",
    "    ng = cv2.imread(\"IC2/ok2_gen/\"+img)\n",
    "    ng = cv2.resize(ng, (160,112), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "#     print(ng)\n",
    "    img_ok2.append(ng)\n",
    "img_ok2 = np.array(img_ok2)\n",
    "print('image in ok2:',img_ok2.shape)\n",
    "\n",
    "i=0\n",
    "for img in ok1:\n",
    "    \n",
    "    while i<1001:\n",
    "        i+=1\n",
    "        ng = cv2.imread(\"IC1/ok/\"+img)\n",
    "        ng = cv2.resize(ng, (160,112), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "#     print(ng)\n",
    "        img_ok1.append(ng)\n",
    "img_ok1 = np.array(img_ok1)\n",
    "print('image in ok1:',img_ok1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # # print(img_ng2[0])\n",
    "# # print(img_ng2[0].shape)\n",
    "# # a = cv2.resize(img_ng2[0], (300,100))\n",
    "# # print(a.shape)\n",
    "# a = img_ng2[0]\n",
    "# # a = np.reshape(a, (300,100))\n",
    "# cv2.imshow(\"img\",a)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n",
    "# # print(a.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "製作one hot格式的label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(228, 2)\n",
      "(926, 2)\n",
      "(252, 2)\n",
      "(1001, 2)\n"
     ]
    }
   ],
   "source": [
    "img_ng2_label=[]\n",
    "for i in img_ng2:\n",
    "    img_ng2_label.append([1,0])\n",
    "img_ng2_label = np.array(img_ng2_label)\n",
    "print(img_ng2_label.shape)\n",
    "img_ng1_label=[]\n",
    "for i in img_ng1:\n",
    "    img_ng1_label.append([1,0])\n",
    "img_ng1_label = np.array(img_ng1_label)\n",
    "print(img_ng1_label.shape)\n",
    "img_ok2_label=[]\n",
    "for i in img_ok2:\n",
    "    img_ok2_label.append([0,1])\n",
    "img_ok2_label = np.array(img_ok2_label)\n",
    "print(img_ok2_label.shape)\n",
    "img_ok1_label=[]\n",
    "for i in img_ok1:\n",
    "    img_ok1_label.append([0,1])\n",
    "img_ok1_label = np.array(img_ok1_label)\n",
    "print(img_ok1_label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 照片預處理()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.灰階"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(228, 112, 160)\n",
      "(926, 112, 160)\n",
      "(252, 112, 160)\n",
      "(1001, 112, 160)\n"
     ]
    }
   ],
   "source": [
    "gray_ng2=[]\n",
    "gray_ng1=[]\n",
    "gray_ok2=[]\n",
    "gray_ok1=[]\n",
    "\n",
    "for img in img_ng2:\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    gray_ng2.append(gray)\n",
    "gray_ng2 = np.array(gray_ng2)\n",
    "# gray_ng2 = np.reshape(gray_ng2, (57,247,363,1))\n",
    "print(gray_ng2.shape)\n",
    "for img in img_ng1:\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    gray_ng1.append(gray)\n",
    "gray_ng1 = np.array(gray_ng1)\n",
    "# gray_ng1 = np.reshape(gray_ng1, (57,247,363,1))\n",
    "print(gray_ng1.shape)\n",
    "for img in img_ok2:\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    gray_ok2.append(gray)\n",
    "gray_ok2 = np.array(gray_ok2)\n",
    "# gray_ng2 = np.reshape(gray_ng2, (57,247,363,1))\n",
    "print(gray_ok2.shape)\n",
    "for img in img_ok1:\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    gray_ok1.append(gray)\n",
    "gray_ok1 = np.array(gray_ok1)\n",
    "# gray_ng2 = np.reshape(gray_ng2, (57,247,363,1))\n",
    "print(gray_ok1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.正規化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.17647059 0.18039216 0.18431373 ... 0.17647059 0.18039216 0.18431373]\n",
      " [0.18039216 0.18039216 0.18039216 ... 0.17647059 0.18039216 0.18823529]\n",
      " [0.18039216 0.18039216 0.18039216 ... 0.18431373 0.18431373 0.18823529]\n",
      " ...\n",
      " [0.22352941 0.23137255 0.23921569 ... 0.50588235 0.42745098 0.3254902 ]\n",
      " [0.2        0.2        0.20392157 ... 0.5372549  0.45490196 0.3254902 ]\n",
      " [0.18039216 0.18431373 0.18431373 ... 0.56862745 0.45882353 0.31764706]]\n"
     ]
    }
   ],
   "source": [
    "gray_ng2=gray_ng2/255\n",
    "gray_ng1=gray_ng1/255\n",
    "gray_ok2=gray_ok2/255\n",
    "gray_ok1=gray_ok1/255\n",
    "print(gray_ng2[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.資料整併，並將訓練與測試分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1927, 112, 160)\n",
      "(1927, 2)\n",
      "(480, 112, 160)\n",
      "(480, 2)\n"
     ]
    }
   ],
   "source": [
    "# train = gray_ok2.append(gray_ng1)\n",
    "train = np.concatenate((gray_ok1,gray_ng1),axis=0)\n",
    "target = np.concatenate((img_ok1_label,img_ng1_label),axis=0)\n",
    "train2 = np.concatenate((gray_ok2,gray_ng2), axis=0)\n",
    "target2 = np.concatenate((img_ok2_label,img_ng2_label),axis=0)\n",
    "\n",
    "# target = img_ok1_label.append(img_ng1_label)\n",
    "\n",
    "print(train.shape)\n",
    "print(target.shape)\n",
    "print(train2.shape)\n",
    "print(target2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(578, 112, 160) (240, 112, 160)\n",
      "(1349, 112, 160) (240, 112, 160)\n",
      "(578, 2) (240, 2)\n",
      "(1349, 2) (240, 2)\n",
      "(818, 112, 160)\n",
      "(818, 2)\n",
      "(1589, 112, 160)\n",
      "(1589, 2)\n"
     ]
    }
   ],
   "source": [
    "X_train1,  X_test1, y_train1, y_test1 = train_test_split(train, target, test_size=0.7)\n",
    "X_train2,  X_test2, y_train2, y_test2 = train_test_split(train2, target2, test_size=0.5)\n",
    "\n",
    "print(X_train1.shape, X_train2.shape)\n",
    "print(X_test1.shape, X_test2.shape)\n",
    "print(y_train1.shape, y_train2.shape)\n",
    "print(y_test1.shape, y_test2.shape)\n",
    "\n",
    "X_train = np.concatenate((X_train1,X_train2),axis=0)\n",
    "y_train = np.concatenate((y_train1,y_train2),axis=0)\n",
    "X_test = np.concatenate((X_test1,X_test2),axis=0)\n",
    "y_test = np.concatenate((y_test1,y_test2),axis=0)\n",
    "\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.調整資料形狀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(818, 112, 160, 1)\n",
      "(1589, 112, 160, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.reshape(X_train, (818, 112, 160,1))\n",
    "X_test = np.reshape(X_test, (1589, 112, 160,1))\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 建造並訓練模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "input_shape =[112, 160,1]\n",
    "\n",
    "model.add(Conv2D(input_shape = input_shape,\n",
    "                 filters = 5,\n",
    "                 kernel_size = (5,5),\n",
    "                 padding = 'same',\n",
    "                 activation = 'relu',\n",
    "                 ))\n",
    "model.add(MaxPooling2D(\n",
    "                       pool_size = (2,2)\n",
    "                       ))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(filters = 10,\n",
    "                 kernel_size = (5,5),\n",
    "                 padding = 'same',\n",
    "                 activation = 'relu'\n",
    "                 ))\n",
    "model.add(MaxPooling2D(\n",
    "                       pool_size = (2,2)\n",
    "                       ))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(\n",
    "                units = 10,\n",
    "                activation = 'relu'\n",
    "                ))\n",
    "\n",
    "model.add(Dense(\n",
    "                units = 2,\n",
    "                activation = 'softmax'\n",
    "                ))\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 736 samples, validate on 82 samples\n",
      "Epoch 1/25\n",
      "736/736 [==============================] - 10s 13ms/step - loss: 0.5940 - acc: 0.7174 - val_loss: 0.7016 - val_acc: 0.4634\n",
      "Epoch 2/25\n",
      "736/736 [==============================] - 9s 13ms/step - loss: 0.2840 - acc: 0.9307 - val_loss: 0.4453 - val_acc: 0.7927\n",
      "Epoch 3/25\n",
      "736/736 [==============================] - 9s 13ms/step - loss: 0.1575 - acc: 0.9470 - val_loss: 0.2989 - val_acc: 0.8780\n",
      "Epoch 4/25\n",
      "736/736 [==============================] - 9s 13ms/step - loss: 0.0820 - acc: 0.9728 - val_loss: 0.2240 - val_acc: 0.9146\n",
      "Epoch 5/25\n",
      "736/736 [==============================] - 9s 13ms/step - loss: 0.0532 - acc: 0.9837 - val_loss: 0.1149 - val_acc: 0.9634\n",
      "Epoch 6/25\n",
      "736/736 [==============================] - 9s 13ms/step - loss: 0.0322 - acc: 0.9932 - val_loss: 0.1196 - val_acc: 0.9634\n",
      "Epoch 7/25\n",
      "736/736 [==============================] - 9s 13ms/step - loss: 0.0224 - acc: 0.9918 - val_loss: 0.0794 - val_acc: 0.9634\n",
      "Epoch 8/25\n",
      "736/736 [==============================] - 9s 13ms/step - loss: 0.0155 - acc: 0.9946 - val_loss: 0.1623 - val_acc: 0.9512\n",
      "Epoch 9/25\n",
      "736/736 [==============================] - 9s 13ms/step - loss: 0.0230 - acc: 0.9932 - val_loss: 0.0599 - val_acc: 0.9634\n",
      "Epoch 10/25\n",
      "736/736 [==============================] - 9s 13ms/step - loss: 0.0137 - acc: 0.9973 - val_loss: 0.0527 - val_acc: 0.9634\n",
      "Epoch 11/25\n",
      "736/736 [==============================] - 9s 13ms/step - loss: 0.0121 - acc: 0.9973 - val_loss: 0.0529 - val_acc: 0.9634\n",
      "Epoch 12/25\n",
      "736/736 [==============================] - 9s 13ms/step - loss: 0.0150 - acc: 0.9932 - val_loss: 0.0652 - val_acc: 0.9634\n",
      "Epoch 13/25\n",
      "736/736 [==============================] - 9s 13ms/step - loss: 0.0101 - acc: 0.9973 - val_loss: 0.0712 - val_acc: 0.9634\n",
      "Epoch 14/25\n",
      "736/736 [==============================] - 9s 13ms/step - loss: 0.0167 - acc: 0.9946 - val_loss: 0.0848 - val_acc: 0.9634\n",
      "Epoch 15/25\n",
      "736/736 [==============================] - 10s 13ms/step - loss: 0.0042 - acc: 1.0000 - val_loss: 0.0819 - val_acc: 0.9634\n",
      "Epoch 16/25\n",
      "736/736 [==============================] - 10s 13ms/step - loss: 0.0318 - acc: 0.9905 - val_loss: 0.1170 - val_acc: 0.9512\n",
      "Epoch 17/25\n",
      "736/736 [==============================] - 10s 13ms/step - loss: 0.0135 - acc: 0.9959 - val_loss: 0.0533 - val_acc: 0.9756\n",
      "Epoch 18/25\n",
      "736/736 [==============================] - 9s 13ms/step - loss: 0.0381 - acc: 0.9823 - val_loss: 0.1344 - val_acc: 0.9512\n",
      "Epoch 19/25\n",
      "736/736 [==============================] - 9s 13ms/step - loss: 0.0179 - acc: 0.9959 - val_loss: 0.0474 - val_acc: 0.9756\n",
      "Epoch 20/25\n",
      "736/736 [==============================] - 9s 13ms/step - loss: 0.0059 - acc: 1.0000 - val_loss: 0.0279 - val_acc: 1.0000\n",
      "Epoch 21/25\n",
      "736/736 [==============================] - 9s 13ms/step - loss: 0.0039 - acc: 0.9986 - val_loss: 0.0593 - val_acc: 0.9634\n",
      "Epoch 22/25\n",
      "736/736 [==============================] - 9s 13ms/step - loss: 0.0031 - acc: 0.9986 - val_loss: 0.0638 - val_acc: 0.9634\n",
      "Epoch 23/25\n",
      "736/736 [==============================] - 9s 13ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0305 - val_acc: 0.9756\n",
      "Epoch 24/25\n",
      "736/736 [==============================] - 9s 13ms/step - loss: 0.0038 - acc: 0.9986 - val_loss: 0.0429 - val_acc: 0.9634\n",
      "Epoch 25/25\n",
      "736/736 [==============================] - 9s 13ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0163 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "train_history = model.fit(X_train,y_train, batch_size=32, validation_split=0.1,verbose=1,epochs=25)   #epochs ~ 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 驗證模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1589/1589 [==============================] - 11s 7ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0032901010832698317, 0.9993706733794839]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict = model.predict(X_test)\n",
    "model.evaluate(X_test,y_test,verbose=1,batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分析錯誤成因"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 依據softmax特性找出'判定錯誤'與'信心低'的資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1589\n",
      "----------------error---------------\n",
      "ng but not found: []\n",
      "ng but not found: []\n",
      "ok but predict error: [1430]\n",
      "ok but predict error: [0.5909069]\n",
      "----------------error---------------\n",
      "\n",
      " \n",
      "\n",
      "--------------confidency---------------\n",
      "ng confidency low: []\n",
      "ng confidency low: []\n",
      "ok confidency low: []\n",
      "ok confidency low: []\n",
      "--------------confidency---------------\n"
     ]
    }
   ],
   "source": [
    "predict = model.predict(X_test)\n",
    "print(len(X_test))\n",
    "err_idx_ng=[]\n",
    "err_idx_ok=[]\n",
    "err_value_ng=[]\n",
    "err_value_ok=[]\n",
    "for i in range(len(y_test)):\n",
    "    if y_test[i][0] - predict[i][0]>0.5:\n",
    "        err_idx_ng.append(i)\n",
    "        err_value_ng.append(predict[i][0])\n",
    "    elif y_test[i][0] - predict[i][0]< -0.5:\n",
    "        err_idx_ok.append(i)\n",
    "        err_value_ok.append(predict[i][0])\n",
    "print('----------------error---------------')\n",
    "print('ng but not found:',err_idx_ng)\n",
    "print('ng but not found:',err_value_ng)\n",
    "\n",
    "print('ok but predict error:',err_idx_ok)\n",
    "print('ok but predict error:',err_value_ok)\n",
    "print('----------------error---------------')\n",
    "print('\\n','\\n')\n",
    "\n",
    "idx_ok=[]\n",
    "idx_ng=[]\n",
    "value_ok=[]\n",
    "value_ng=[]\n",
    "\n",
    "for i in range(len(y_test)):\n",
    "    if predict[i][0]>0.5 and predict[i][0]<0.55:\n",
    "        idx_ok.append(i)\n",
    "        value_ok.append(predict[i][0])\n",
    "    elif predict[i][0]< 0.5 and predict[i][0]>0.45:\n",
    "        idx_ng.append(i)\n",
    "        value_ng.append(predict[i][0])\n",
    "print('--------------confidency---------------')\n",
    "print('ng confidency low:',idx_ok)\n",
    "print('ng confidency low:',value_ok)\n",
    "\n",
    "print('ok confidency low:',idx_ng)\n",
    "print('ok confidency low:',value_ng)\n",
    "print('--------------confidency---------------')\n",
    "\n",
    "# predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 將錯誤圖片秀出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for err in err_idx_ng:\n",
    "    cv2.imshow('img'+str(err),X_test[err])\n",
    "for err in err_idx_ok:\n",
    "    cv2.imshow('img'+str(err),X_test[err])\n",
    "for idx in idx_ok:\n",
    "    cv2.imshow('img'+str(idx),X_test[idx])\n",
    "for idx in idx_ng:\n",
    "    cv2.imshow('img'+str(idx),X_test[idx])\n",
    "    \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
